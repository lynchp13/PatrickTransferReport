\chapter{Computation}

Copy, Paste and modify the current draft of the botmark paper



Robotic competitions are fast becoming the \textit{de facto} standard for benchmarking robots in the field of service robotics. In this chapter, present a benchmarking suite is presented. It is designed specifically for evaluating the performance of computer platforms for performing functions common to these competitions, including manipulating tasks. An brief overview of computer benchmarking is firstly given along with popular robotic competitions relevant to service robotics. We take the RoboCup@Home competition as a prototypical exemplar of these  and develop a set of workloads based on the tests and functions that comprise it using a composite approach of the competing teams. The workloads are then run across a variety of computer platforms representative of the type commonly used and the results are presented. Other considerations are also investigated such as the power consumption, ease of development, I/O capabilities, price, size, etc. A wide variability is seen between computer systems. Finally, MORE HERE WHEN RESULTS ARE FOUND.


\section{Algorithms}

\section{Test Platforms}

Intel i5 Laptop 
Intel i7 
Parallela
Mini-ITX
Raspberry Pi
Intel Joule
NVIDIA P2597

\section{Methodology}
\subsection{Experimental Set-up}
\subsection{Evaluation Metrics}
Speed
Robustness
Accuracy
Range of Objects
Success Rate

\section{Results}


\section{Discussion}






