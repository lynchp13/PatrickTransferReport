@INPROCEEDINGS{UnderactuationReductionInActuactors, 
author={Yuwang Liu and Hongguang Wang and Bin Li and Weijia Zhou}, 
booktitle={2008 IEEE International Conference on Robotics and Biomimetics}, 
title={The underactuation and motion-coupling in robotic fingers and two new 1-DOF motion-coupling anthropomorphic fingers}, 
year={2009}, 
volume={}, 
number={}, 
pages={1573-1578}, 
keywords={actuators;dexterous manipulators;robotic fingers;motion-coupling anthropomorphic fingers;multiflngered hands;motion-coupling underactuation;3D-CAD model;anthropomorphic hand;Fingers;Robots;Anthropomorphism;Actuators;Motion analysis;Couplings;Orbital robotics;Hardware;Prosthetics;Application software;robotic finger;underactuation;motion-coupling;anthropomorphic}, 
doi={10.1109/ROBIO.2009.4913235}, 
ISSN={}, 
month={Feb},}

@INPROCEEDINGS{DisneyRobot, 
author={J. Kober and M. Glisson and M. Mistry}, 
booktitle={2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012)}, 
title={Playing catch and juggling with a humanoid robot}, 
year={2012}, 
volume={}, 
number={}, 
pages={875-881}, 
keywords={dexterous manipulators;humanoid robots;Kalman filters;robot vision;entertainment robots;theme park environments;theme park type animatronic humanoid robot;throwing game scenario;catching game scenario;external camera system;ASUS Xtion PRO LIVE;Kalman filter;ball destination prediction;robot hand;vision coordinate system;least-squares technique;human partner juggling;robot partner juggling;ball cascade pattern;catching cycle;throwing cycle;juggling system;skilled jugglers;Cameras;Robot vision systems;Machine vision;Joints;Trajectory}, 
doi={10.1109/HUMANOIDS.2012.6651623}, 
ISSN={2164-0572}, 
month={Nov},}

@INPROCEEDINGS{ConveyorBeltTracking, 
author={R. C. Luo and C. Liao}, 
booktitle={2017 IEEE 15th International Conference on Industrial Informatics (INDIN)}, 
title={Robotic conveyor tracking with dynamic object fetching for industrial automation}, 
year={2017}, 
volume={}, 
number={}, 
pages={369-374}, 
keywords={conveyors;industrial manipulators;manipulator dynamics;mobile robots;object recognition;robot vision;fetching tasks;visual feedback system;optimization algorithms;object recognition;visual system;robotic conveyor;dynamic object fetching;industrial automation;industrial robotic applications;conveyor tracking;robot manipulator;production line;sophisticated problems;distinct grasping method;visual control system;tracking strategy;robot arm object fetching system;industrial tracking;7-DoF robot arm;Manipulators;Service robots;Robot sensing systems;Robot kinematics;Target tracking}, 
doi={10.1109/INDIN.2017.8104800}, 
ISSN={2378-363X}, 
month={July},}

@INPROCEEDINGS{ConveyorUnknownObject, 
author={S. Escaida Navarro and D. Weiss and D. Stogl and D. Milev and B. Hein}, 
booktitle={ISR/Robotik 2014; 41st International Symposium on Robotics}, 
title={Tracking and Grasping of Known and Unknown Objects from a Conveyor Belt}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-8}, 
keywords={}, 
doi={}, 
ISSN={}, 
month={June},}


@ARTICLE{GRASPTaxonomy, 
author={T. {Feix} and J. {Romero} and H. {Schmiedmayer} and A. M. {Dollar} and D. {Kragic}}, 
journal={IEEE Transactions on Human-Machine Systems}, 
title={The GRASP Taxonomy of Human Grasp Types}, 
year={2016}, 
volume={46}, 
number={1}, 
pages={66-77}, 
keywords={control engineering computing;haptic interfaces;human computer interaction;manipulators;virtual reality;GRASP taxonomy;human grasp type;human grasp taxonomy;European Commission;static grasp;stable grasp;human hand configuration;human-computer interaction;tangible user interface;virtual finger assignment;grasp definition;classification;Taxonomy;Thumb;Force;Robots;Grasping;Shape;Man machine systems;Hand/wrist posture;human–robot interaction;taxonomies;robotics;human factors;Hand/wrist posture;human–robot interaction;taxonomies;robotics;human factors}, 
doi={10.1109/THMS.2015.2470657}, 
ISSN={2168-2291}, 
month={Feb},}

@article{Reconf3Finger,
abstract = {This paper proposes a method for modeling and planning the grasping configuration of a robotic hand with underactuated finger mechanisms. The proposed modeling algorithm is based on analysis and mimicking of human grasping experience. Results of the analysis is preprocessed and stored in a database. The grasp configuration planning algorithm can be used within a real time online grasp control as based on artificial neural networks. Namely, shapes and sizes of task objects are described by taxonomy data, which are used to generate grasp configurations. Then, a robot hand grasp control system is designed as based on the proposed grasp planning with close-loop position and force feedback. Simulations and experiments are carried out to show the basic features of the proposed formulation for identifying the grasp configurations while dealing with target objects of different shapes and sizes. It is hoped that the well-trained underactuated robot hand can solve most of grasping tasks in our life. The research approach is aimed to research low-cost easy-operation solution for feasible and practical implementation.},
author = {Yao, Shuangji and Ceccarelli, Marco and Carbone, Giuseppe and Dong, Zhikui},
doi = {10.1016/j.mechmachtheory.2018.06.019},
file = {:home/lynchxps/Documents/Mendeley Desktop/Grasp configuration planning for a low-cost and easy-operation underactuated three-fingered robot hand - Yao et al. - 2018.pdf:pdf},
issn = {0094114X},
journal = {Mechanism and Machine Theory},
keywords = {Experimental testing,Grasp configuration planning,Robotic hand,Simulation,Underactuation},
mendeley-groups = {HandPaper},
pages = {51--69},
publisher = {Elsevier Ltd},
title = {{Grasp configuration planning for a low-cost and easy-operation underactuated three-fingered robot hand}},
url = {https://doi.org/10.1016/j.mechmachtheory.2018.06.019},
volume = {129},
year = {2018}
}

@INPROCEEDINGS{EarlyAnticipation, 
author={D. {Carneiro} and F. {Silva} and P. {Georgieva}}, 
booktitle={2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)}, 
title={The role of early anticipations for human-robot ball catching}, 
year={2018}, 
volume={}, 
number={}, 
pages={10-16}, 
keywords={feedforward neural nets;human-robot interaction;learning (artificial intelligence);position control;robot vision;thrower;feed-forward neural network;flight phase;early anticipation skills;ball catching performance;early anticipations;human-robot ball catching;intention inference;human actions;robots;interactive tasks;robotic system playing ball;human partner;anticipatory information;Trajectory;Robot kinematics;Task analysis;Neural networks;Data mining;Conferences;Human-Robot Interaction;Ball Catching;Machine Learning;Neural Network;Anticipatory Prediction}, 
doi={10.1109/ICARSC.2018.8374153}, 
ISSN={}, 
month={April},}


@article{1991BallTracking,
author = {Hove, Barbara and Slotine, Jean-jacques E},
file = {:home/lynchxps/Documents/Mendeley Desktop/Experiments in Robotic Cathcing - Hove, Slotine - 1991.pdf:pdf},
journal = {American Control Conference},
mendeley-groups = {Transfer Report},
pages = {380--386},
title = {{Experiments in Robotic Cathcing}},
year = {1991}
}

@INPROCEEDINGS{2001OffTheShelf, 
author={U. {Frese} and B. {Bauml} and S. {Haidacher} and G. {Schreiber} and I. {Schaefer} and M. {Hahnle} and G. {Hirzinger}}, 
booktitle={Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180)}, 
title={Off-the-shelf vision for a robotic ball catcher}, 
year={2001}, 
volume={3}, 
number={}, 
pages={1623-1629 vol.3}, 
keywords={nonlinear filters;Kalman filters;robot vision;image segmentation;image colour analysis;motion control;manipulator dynamics;off-the-shelf vision;robotic ball catcher;flying ball;robot arm;visual tracking;large baseline stereo camera;slowly adapting reference image;extended Kalman filter;Robot vision systems;Cameras;Target tracking;Robustness;Shape;Mechatronics;Calibration;Hardware;Object detection;Object recognition}, 
doi={10.1109/IROS.2001.977211}, 
ISSN={}, 
month={Oct},}


@INPROCEEDINGS{Saika, 
author={K. {Nishiwaki} and A. {Ionno} and K. {Nagashima} and M. {Inaba} and H. {Inoue}}, 
booktitle={Proceedings 6th IEEE International Workshop on Robot and Human Communication. RO-MAN'97 SENDAI}, 
title={The humanoid Saika that catches a thrown ball}, 
year={1997}, 
volume={}, 
number={}, 
pages={94-99}, 
keywords={robot vision;manipulator kinematics;neurocontrollers;Saika;humanoid robot;ball-catching behavior;dynamic skilful manipulation;localization;vision system;catching point;neural network inverse kinematics model;Humans;Humanoid robots;Predictive models;Manipulator dynamics;Robot kinematics;Control systems;Neural networks;Robot vision systems;Cameras;Arm}, 
doi={10.1109/ROMAN.1997.646959}, 
ISSN={}, 
month={Sep.},}

@article{HandEye,
abstract = {Robot hand-eye coordination has recently enjoyed much attention. Previous research at MIT has examined combining vision and manipulation applied to the task of tracking and catching tossed balls in controlled environments. Building upon the foundations of this past research, this paper presents work which incorporates a new active vision system which requires a minimally controlled environment, and implements methods for object tracking, robot/camera calibration, and new catching algorithms. Experimental results for real time catching of free-flying spherical balls are presented. The system was tested on under-hand tosses from random locations approximately 1.5-2.5 meters distant from the base of the arm. The best performance results were found to be 70-80{\%} success for similar tosses.$\backslash$n},
author = {Hong, Won and Slotine, Jean-Jacques E.},
doi = {10.1007/bfb0035204},
file = {:home/lynchxps/Documents/Mendeley Desktop/Experiments in hand-eye coordination using active vision - Hong, Slotine - 2005.pdf:pdf},
journal = {Experimental Robotics IV},
mendeley-groups = {Transfer Report},
pages = {130--139},
title = {{Experiments in hand-eye coordination using active vision}},
year = {2005}
}

@INPROCEEDINGS{RollinJustin, 
author={B. {Bäuml} and F. {Schmidt} and T. {Wimböck} and O. {Birbach} and A. {Dietrich} and M. {Fuchs} and W. {Friedl} and U. {Frese} and C. {Borst} and M. {Grebenstein} and O. {Eiberger} and G. {Hirzinger}}, 
booktitle={2011 IEEE International Conference on Robotics and Automation}, 
title={Catching flying balls and preparing coffee: Humanoid Rollin'Justin performs dynamic and sensitive tasks}, 
year={2011}, 
volume={}, 
number={}, 
pages={3443-3444}, 
keywords={humanoid robots;manipulator kinematics;mobile robots;sensors;mobile humanoid system;Rollin'Justin system;manipulation tasks;autonomous task execution scenarios;flying balls;autonomous coffee preparation;sensor information;kinematic sub-chains;Software;Joints;Mobile communication;Robot sensing systems;Torso}, 
doi={10.1109/ICRA.2011.5980073}, 
ISSN={1050-4729}, 
month={May},}

@article{TennisRacket,
abstract = {We address the difficult problem of catching in-flight objects with uneven shapes. This requires the solution of three complex problems: accurate prediction of the trajectory of fast-moving objects, predicting the feasible catching configuration, and planning the arm motion, and all within milliseconds. We follow a programming-by-demonstration approach in order to learn, from throwing examples, models of the object dynamics and arm movement. We propose a new methodology to find a feasible catching configuration in a probabilistic manner. We use the dynamical systems approach to encode motion from several demonstrations. This enables a rapid and reactive adaptation of the arm motion in the presence of sensor uncertainty. We validate the approach in simulation with the iCub humanoid robot and in real-world experiments with the KUKA LWR 4+ (7-degree-of-freedom arm robot) to catch a hammer, a tennis racket, an empty bottle, a partially filled bottle, and a cardboard box.},
author = {Kim, Seungsu and Shukla, Ashwini and Billard, Aude},
doi = {10.1109/TRO.2014.2316022},
file = {:home/lynchxps/Documents/Mendeley Desktop/Catching objects in flight - Kim, Shukla, Billard - 2014.pdf:pdf},
isbn = {1552-3098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Catching,Gaussian mixture model,machine learning,robot control,support vector machines},
mendeley-groups = {HandPaper,IROS BIB},
number = {5},
pages = {1049--1065},
title = {{Catching objects in flight}},
volume = {30},
year = {2014}
}

@article{JugglingWithKitchenFunnels,
abstract = {Our focus is on creating interesting and human-like behaviors for humanoid robots and virtual characters. Interactive behaviors are especially engaging. They are also challenging, as they necessitate finding satisfactory realtime solutions for complex systems such as the 30-degree-of-freedom humanoid robot in our laboratory. Here we describe a catching behavior between a person and a robot. We generate ball-hand impact predictions based on the flight of the ball, and human-like motion trajectories to move the hand to the catch position. We use a dynamical systems approach to produce the motion trajectories where new movements are generated from motion primitives as they are needed.},
author = {Riley, Marcia and Atkeson, Christopher G.},
doi = {10.1023/A:1013223328496},
file = {:home/lynchxps/Documents/Mendeley Desktop/Robot catching Towards engaging human-humanoid interaction - Riley, Atkeson - 2002.pdf:pdf},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {Biologically-inspired robotics,Dynamical systems,Human-like,Humanoid,Interactive robot behavior,Robot catching,Trajectory generation},
mendeley-groups = {Transfer Report},
number = {1},
pages = {119--128},
title = {{Robot catching: Towards engaging human-humanoid interaction}},
volume = {12},
year = {2002}
}

@article{KinematicallyOptimal,
abstract = {A robotic ball-catching system built from a multi-purpose 7-DOF lightweight arm (DLR-LWR-III) and a 12 DOF four-fingered hand (DLR-Hand-II) is presented. Other than in previous work a mechatronically complex dexterous hand is used for grasping the ball and the decision of where, when and how to catch the ball, while obeying joint, speed and work cell limits, is formulated as an unified nonlinear optimization problem with nonlinear constraints. Three different objective functions are implemented, leading to significantly different robot movements. The high computational demands of an online realtime optimization are met by parallel computation on distributed computing resources (a cluster with 32 CPU cores). The system achieves a catch rate of {\&}gt; 80{\%} and is regularly shown as a live demo at our institute.},
author = {B{\"{a}}uml, Berthold and Wimb{\"{o}}ck, Thomas and Hirzinger, Gerd},
doi = {10.1109/IROS.2010.5651175},
file = {:home/lynchxps/Documents/Mendeley Desktop/Kinematically optimal catching a flying ball with a hand-arm-system - B{\"{a}}uml, Wimb{\"{o}}ck, Hirzinger - 2010.pdf:pdf},
isbn = {9781424466757},
issn = {2153-0858},
journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
mendeley-groups = {HandPaper},
pages = {2592--2599},
title = {{Kinematically optimal catching a flying ball with a hand-arm-system}},
year = {2010}
}

@misc{OneHandedJuggling,
abstract = {The skill of rhythmically juggling a ball on a racket was investigated from the viewpoint of nonlinear dynamics. The difference equations that model the dynamical system were analyzed by means of local and nonlocal stability analyses. These analyses showed that the task dynamics offer an economical juggling pattern that is stable even for open-loop actuator motion. For this pattern, two types of predictions were extracted: (a) Stable periodic bouncing is sufficiently characterized by a negative acceleration of the racket at the moment of impact with the ball, and (b) a nonlinear scaling relation maps different juggling trajectories onto one topologically equivalent dynamical system. The relevance of these results for the human control of action was evaluated in an experiment in which subjects (N = 6) performed a comparable task of juggling a ball on a paddle. Task manipulations involved different juggling heights and gravity conditions of the ball. The following predictions were confirmed: (a) For stable rhythmic performance, the paddle's acceleration at impact is negative and fluctuations of the impact acceleration follow predictions from global stability analysis; and (b) for each subject, the realizations of juggling for the different experimental conditions are related by the scaling relation. These results permit one to conclude that humans reliably exploit the stable solutions inherent to the dynamics of the given task and do not overrule these dynamics by other control mechanisms. The dynamical scaling serves as an efficient principle for generating different movement realizations from only a few parameter changes and is discussed as a dynamical formalization of the principle of motor equivalence.},
author = {Schaal, Stefan and Atkeson, Christopher G. and Sternad, Dagmar},
booktitle = {Journal of Motor Behavior},
doi = {10.1080/00222895.1996.9941743},
file = {:home/lynchxps/Documents/Mendeley Desktop/One-Handed Juggling A Dynamical Approach to a Rhythmic Movement Task - Schaal, Atkeson, Sternad - 1996.pdf:pdf},
issn = {19401027},
keywords = {Juggling,Motor control,Motor equivalence,Nonlinear dynamics,Stability analysis},
mendeley-groups = {Transfer Report},
number = {2},
pages = {165--183},
title = {{One-Handed Juggling: A Dynamical Approach to a Rhythmic Movement Task}},
volume = {28},
year = {1996}
}

@article{Shukla2012,
abstract = {Performing manipulation tasks interactively in real environments requires a high degree of accuracy and stability. At the same time, when one cannot assume a fully deterministic and static environment, one must endow the robot with the ability to react rapidly to sudden changes in the environment. These considerations make the task of reach and grasp difficult to deal with. We follow a Programming by Demonstration (PbD) approach to the problem and take inspiration from the way humans adapt their reach and grasp motions when perturbed. This is in sharp contrast to previous work in PbD that uses unperturbed motions for training the system and then applies perturbation solely during the testing phase. In this work, we record the kinematics of arm and fingers of human subjects during unperturbed and perturbed reach and grasp motions. In the perturbed demonstrations, the target's location is changed suddenly after the onset of the motion. Data show a strong coupling between the hand transport and finger motions. We hypothesize that this coupling enables the subject to seamlessly and rapidly adapt the finger motion in coordination with the hand posture. To endow our robot with this competence, we develop a coupled dynamical system based controller, whereby two dynamical systems driving the hand and finger motions are coupled. This offers a compact encoding for reach-to-grasp motions that ensures fast adaptation with zero latency for re-planning. We show in simulation and on the real iCub robot that this coupling ensures smooth and "human-like" motions. We demonstrate the performance of our model under spatial, temporal and grasp type perturbations which show that reaching the target with coordinated handarm motion is necessary for the success of the task. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Shukla, Ashwini and Billard, Aude},
doi = {10.1016/j.robot.2011.07.023},
file = {:home/lynchxps/Documents/Mendeley Desktop/Coupled dynamical system based arm-hand grasping model for learning fast adaptation strategies - Shukla, Billard - 2012.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Fast perturbations,Grasping,Handarm coordination,Manipulation planning,Programming by demonstration},
mendeley-groups = {Transfer Report},
number = {3},
pages = {424--440},
publisher = {Elsevier B.V.},
title = {{Coupled dynamical system based arm-hand grasping model for learning fast adaptation strategies}},
url = {http://dx.doi.org/10.1016/j.robot.2011.07.023},
volume = {60},
year = {2012}
}

@article{Zacharias2009,
abstract = {Humans use learned knowledge to solve reaching tasks and tomanipulate objects and tools.We believe that representations of manipulation characteristics of an object and of the reaching capabilities of a robotic arm can speed up low-level planners, like grasp planners. They also enable sophisticated scene analysis and reasoning for high-level planners, like task planners. We present object-specific grasp maps to encapsulate an object's manipulation characteristics.Agrasp planner is shown to use the grasps maps and a representation of the reachableworkspace. The exploitation of the provided knowledge focuses the planning on regions of the object that are promising to yield high quality grasps. Speed ups of factor 2-12 are reported.},
author = {Zacharias, Franziska and Borst, Christoph and Hirzinger, Gerd},
doi = {10.1007/978-3-642-01213-6_19},
file = {:home/lynchxps/Documents/Mendeley Desktop/Object-Specific Grasp Maps for Use in Planning Manipulation Actions - Zacharias, Borst, Hirzinger - Unknown.pdf:pdf},
journal = {Advances in Robotics Research},
mendeley-groups = {Transfer Report},
pages = {203--213},
title = {{Object-Specific Grasp Maps for Use in Planning Manipulation Actions}},
year = {2009}
}

@article{Buhler1989,
author = {B{\"{u}}hler, M and Koditschek, D E and Kindlmann, P J},
file = {:home/lynchxps/Documents/Mendeley Desktop/Planning and Control of Robotic Juggling Tasks - B{\"{u}}hler, Koditschek, Kindlmann - 1989.pdf:pdf},
journal = {International Symposium on Robotics Research},
mendeley-groups = {Transfer Report},
title = {{Planning and Control of Robotic Juggling Tasks}},
year = {1989}
}

@article{Muelling2014,
abstract = {Hitting and batting tasks, such as tennis forehands, ping-pong strokes, or baseball batting, depend on predictions where the ball can be intercepted and how it can properly be returned to the opponent. These predictions get more accurate over time, hence the behaviors need to be continuously modified. As a result, movement templates with a learned global shape need to be adapted during the execution so that the racket reaches a target position and velocity that will return the ball over to the other side of the net or court. It requires altering learned movements to hit a varying target with the necessary velocity at a specific instant in time. Such a task cannot be incorporated straightforwardly in most movement representations suitable for learning. For example, the standard formulation of the dynamical system based motor primitives (introduced by Ijspeert et al. [1]) does not satisfy this property despite their flexibility which has allowed learning tasks ranging from locomotion to kendama. In order to fulfill this requirement, we reformulate the Ijspeert framework to incorporate the possibility of specifying a desired hitting point and a desired hitting velocity while maintaining all advantages of the original formulation. We show that the proposed movement template formulation works well in two scenarios, i.e., for hitting a ball on a string with a table tennis racket at a specified velocity and for returning balls launched by a ball gun successfully over the net using forehand movements. All experiments were carried out on a Barrett WAM using a four camera vision system.},
author = {Muelling, Katharina and Kroemer, Oliver and Lampert, Christoph H. and Sch{\"{o}}lkopf, Bernhard},
doi = {10.1007/978-3-319-03194-1_3},
file = {:home/lynchxps/Documents/Mendeley Desktop/Movement Templates for Learning of Hitting and Batting - Muelling et al. - 2014.pdf:pdf},
isbn = {9781424450404},
issn = {1610742X},
journal = {Springer Tracts in Advanced Robotics},
mendeley-groups = {Transfer Report},
pages = {69--82},
title = {{Movement Templates for Learning of Hitting and Batting}},
volume = {97},
year = {2014}
}

@article{Senoo2006,
abstract = {Speeding up robot motion provides not only improvement in operating efficiency but also improves dexterous manipulation by taking advantage of an unstable state or noncontact state. In this paper we describe a hybrid trajectory generator that produces high-speed manipulation. This algorithm produces both mechanical high-speed motion and sensor-based reactive motion. As an example of high-speed manipulation, a robotic ball control in a batting task has been achieved. Performance evaluation is also analyzed},
author = {Senoo, Taku and Namiki, Akio and Ishikawa, Masatoshi},
doi = {10.1109/ROBOT.2006.1641961},
file = {:home/lynchxps/Documents/Mendeley Desktop/Ball control in high-speed batting motion using hybrid trajectory generator - Senoo, Namiki, Ishikawa - 2006.pdf:pdf},
isbn = {0780395069},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Transfer Report},
number = {May},
pages = {1762--1767},
publisher = {IEEE},
title = {{Ball control in high-speed batting motion using hybrid trajectory generator}},
volume = {2006},
year = {2006}
}

@misc{Anderson1989,
abstract = {Our robot ping-pong system attains good performance in a complex non-linear environment subject to tight temporal constraints. We will show how the expert controller combines approximate estimates and feedback to arrive at a suitable task plan, emphasizing feasibility rather than strict optimally. We will discuss the characteristic of the expert controller that cause it to work, and their relationship to other tasks.},
author = {Anderson, Russell},
file = {:home/lynchxps/Documents/Mendeley Desktop/UnderstandingAndApplyingARobotPingPongPlayerExpertController.pdf - Anderson - 1989.pdf:pdf},
mendeley-groups = {Transfer Report},
title = {{UnderstandingAndApplyingARobotPingPongPlayerExpertController.pdf}},
year = {1989}
}

@article{Lampariello2011,
abstract = {Many real-world tasks require fast planning of highly dynamic movements for their execution in real-time. The success often hinges on quickly finding one of the few plans that can achieve the task at all. A further challenge is to quickly find a plan which optimizes a desired cost. In this paper, we will discuss this problem in the context of catching small flying targets efficiently. This can be formulated as a non-linear optimization problem where the desired trajectory is encoded by an adequate parametric representation. The optimizer generates an energy-optimal trajectory by efficiently using the robot kinematic redundancy while taking into account maximal joint motion, collision avoidance and local minima. To enable the resulting method to work in real-time, examples of the global planner are generalized using nearest neighbour approaches, Support Vector Machines and Gaussian process regression, which are compared in this context. Evaluations indicate that the presented method is highly efficient in complex tasks such as ball-catching.},
author = {Lampariello, Roberto and Nguyen-Tuong, Duy and Castellini, Claudio and Hirzinger, Gerd and Peters, Jan},
doi = {10.1109/ICRA.2011.5980114},
file = {:home/lynchxps/Documents/Mendeley Desktop/Trajectory planning for optimal robot catching in real-time - Lampariello et al. - 2011.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Transfer Report},
pages = {3719--3726},
publisher = {IEEE},
title = {{Trajectory planning for optimal robot catching in real-time}},
year = {2011}
}

@article{Koc2018,
abstract = {In highly dynamic tasks that involve moving targets, planning is necessary to figure out when, where and how to intercept the target. In robotic table tennis in particular, motion planning can be very challenging due to time constraints, dimension of the search space and joint limits. Conventional planning algorithms often rely on a fixed virtual hitting plane to construct robot striking trajectories. These algorithms, however, generate restrictive strokes and can result in unnatural strategies when compared with human playing. In this paper, we introduce a new trajectory generation framework for robotic table tennis that does not involve a fixed hitting plane. A free-time optimal control approach is used to derive two different trajectory optimizers. The resulting two algorithms, Focused Player and Defensive Player, encode two different play-styles. We evaluate their performance in simulation and in our robot table tennis platform with a high speed cable-driven seven DOF robot arm. The algorithms return the balls with a higher probability to the opponent's court when compared with a virtual hitting plane based method. Moreover, both can be run online and the trajectories can be corrected with new ball observations.},
author = {Ko{\c{c}}, Okan and Maeda, Guilherme and Peters, Jan},
doi = {10.1016/j.robot.2018.03.012},
file = {:home/lynchxps/Documents/Mendeley Desktop/Online optimal trajectory generation for robot table tennis - Ko{\c{c}}, Maeda, Peters - 2018.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Motion planning,Optimal control,Optimization,Robot table tennis},
mendeley-groups = {Transfer Report},
pages = {121--137},
publisher = {Elsevier B.V.},
title = {{Online optimal trajectory generation for robot table tennis}},
url = {https://doi.org/10.1016/j.robot.2018.03.012},
volume = {105},
year = {2018}
}

@InProceedings{RoboCupSoccer,
author="Kitano, Hiroaki
and Asada, Minoru
and Kuniyoshi, Yasuo
and Noda, Itsuki
and Osawai, Eiichi
and Matsubara, Hitoshi",
editor="Kitano, Hiroaki",
title="RoboCup: A challenge problem for AI and robotics",
booktitle="RoboCup-97: Robot Soccer World Cup I",
year="1998",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--19",
abstract="RoboCup is an attempt to foster AI and intelligent robotics research by providing a standard problem where wide range of technologies can be integrated and examined. The first RoboCup competition was held at IJCAI-97, Nagoya. In order for a robot team to actually perform a soccer game, various technologies must be incorporated including: design principles of autonomous agents, multi-agent collaboration, strategy acquisition, real-time reasoning, robotics, and sensorfusion. RoboCup is a task for a team of multiple fast-moving robots under a dynamic environment. Although RoboCup's final target is a world cup with real robots, RoboCup offers a software platform for research on the software aspects of RoboCup. This paper describes technical challenges involved in RoboCup, rules, and simulation environment.",
isbn="978-3-540-69789-3"
}


@article{FuzzyRobocup,
author = {Iqbal, Nadeem},
file = {:home/lynchxps/Documents/Mendeley Desktop/Fuzzy Set Rules for the Ideal Opponent r x-C T E - Iqbal - 2007.pdf:pdf},
isbn = {1424414946},
journal = {Online},
keywords = {autonomous agents,machine learning,multiagent systems,reinforcement learning,robotics},
mendeley-groups = {Transfer Report},
title = {{Fuzzy Set Rules for the Ideal Opponent r x-C ] T [ E}},
year = {2007}
}
@article{AirHockey,
author = {Bishop, Bradley E. and Spong, Mark W.},
doi = {10.1109/37.768537},
file = {:home/lynchxps/Documents/Mendeley Desktop/Vision-Based Control of an Air Hockey Playing Robot - Bishop, Spong - 1999.pdf:pdf},
issn = {1066033X},
journal = {IEEE Control Systems},
mendeley-groups = {Transfer Report},
number = {3},
pages = {23--32},
title = {{Vision-Based Control of an Air Hockey Playing Robot}},
volume = {19},
year = {1999}
}

@article{IceHockey,
abstract = {This paper presents the system used by the team of the German University in Cairo (GUC) within the FESTO Hockey Challenge league that took place within RoboCup 2009. The goal of the FESTO Hockey Challenge is to have a competition between robotic teams where each team consists of three robots to compete in an Ice Hockey game. All robots are of the same mechanical, sensor and electronic capabilities so that the focus of the competition is to develop novel artificial intelligence techniques for robot control and coordination. The GUC team scored the 2nd place in this competition after losing by penalty shoot outs in the final. The proposed control approach for GUC team employed Hierarchical Fuzzy Logic Controllers (HFLCs) in which the low level behaviours are implemented using FLCs and the coordination between the behaviours is implemented by a high level fuzzy layer. The coordination between the robotic agents team members is implemented by a hierarchical situation based dynamic role allocation mechanism. The paper will describe the employed approaches and will report on the results achieved.},
author = {Hagras, Hani and Ramadan, Rabie and Nawito, Mousata and Gabr, Hala and Zaher, Mina and Fahmy, Hussien},
doi = {10.1109/FUZZY.2010.5584496},
file = {:home/lynchxps/Documents/Mendeley Desktop/A fuzzy based hierarchical coordination and control system for a robotic agent team in the robot Hockey competition - Hagras et al. - 20.pdf:pdf},
isbn = {9781424469208},
journal = {2010 IEEE World Congress on Computational Intelligence, WCCI 2010},
mendeley-groups = {Transfer Report},
title = {{A fuzzy based hierarchical coordination and control system for a robotic agent team in the robot Hockey competition}},
year = {2010}
}

@INPROCEEDINGS{Nakamoto2019, 
author={H. {Nakamoto} and M. {Ohtake} and K. {Komoda} and A. {Sugahara} and A. {Ogawa}}, 
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
title={A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching}, 
year={2018}, 
volume={}, 
number={}, 
pages={6093-6098}, 
keywords={force control;grippers;motion control;robust control;trajectory control;vacuum pumps;robust pinching;Amazon Robotics Challenge 2017;suction air;vacuum pump;pad characteristics;gripper system;trajectory planning;trajectory control;suction force;passive linear motion mechanism;Conferences;Intelligent robots}, 
doi={10.1109/IROS.2018.8593887}, 
ISSN={2153-0866}, 
month={Oct},}

@INPROCEEDINGS{APCGripper, 
author={H. {Nakamoto} and M. {Ohtake} and K. {Komoda} and A. {Sugahara} and A. {Ogawa}}, 
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
title={A Gripper System for Robustly Picking Various Objects Placed Densely by Suction and Pinching}, 
year={2018}, 
volume={}, 
number={}, 
pages={6093-6098}, 
keywords={force control;grippers;motion control;robust control;trajectory control;vacuum pumps;robust pinching;Amazon Robotics Challenge 2017;suction air;vacuum pump;pad characteristics;gripper system;trajectory planning;trajectory control;suction force;passive linear motion mechanism;Conferences;Intelligent robots}, 
doi={10.1109/IROS.2018.8593887}, 
ISSN={2153-0866}, 
month={Oct},}

@article{APCObservations,
abstract = {This paper presents a overview of the inaugural Amazon Picking Challenge along with a summary of a survey conducted among the 26 participating teams. The challenge goal was to design an autonomous robot to pick items from a warehouse shelf. This task is currently performed by human workers, and there is hope that robots can someday help increase efficiency and throughput while lowering cost. We report on a 28-question survey posed to the teams to learn about each team's background, mechanism design, perception apparatus, planning and control approach. We identify trends in this data, correlate it with each team's success in the competition, and discuss observations and lessons learned based on survey results and the authors' personal experiences during the challenge.},
archivePrefix = {arXiv},
arxivId = {1601.05484},
author = {Correll, Nikolaus and Bekris, Kostas E. and Berenson, Dmitry and Brock, Oliver and Causo, Albert and Hauser, Kris and Okada, Kei and Rodriguez, Alberto and Romano, Joseph M. and Wurman, Peter R.},
doi = {10.1109/TASE.2016.2600527},
eprint = {1601.05484},
file = {:home/lynchxps/Documents/Mendeley Desktop/First Amazon Picking Challenge - Correll et al. - 2018.pdf:pdf},
journal = {IEEE Transactions on Automation Science and Engineering},
mendeley-groups = {Transfer Report},
number = {1},
pages = {172--188},
publisher = {IEEE},
title = {{Analysis and Observations from the First Amazon Picking Challenge}},
url = {http://arxiv.org/abs/1601.05484},
volume = {15},
year = {2016}
}

@article{CompetitionsAsBenchmarks,
abstract = {{\textless}div class="abstract" data-abstract-type="normal"{\textgreater}{\textless}p{\textgreater}In the last two decades various intelligent robotics competitions have become very popular. Arguably the most well-known of these are the robotic soccer competitions. In addition to their value in attracting media and capturing the minds of the general public, these competitions also provide benchmark problems for various robotics and artificial intelligence (AI) technologies. As with any benchmark, care must be taken that the benchmark does not introduce unwarranted biases. This paper critically evaluates the AI contributions made by various robotic competitions on AI research.{\textless}/p{\textgreater}{\textless}/div{\textgreater}},
author = {Anderson, John and Baltes, Jacky and Cheng, Chi Tai},
doi = {10.1017/S0269888910000354},
file = {:home/lynchxps/Documents/Mendeley Desktop/Robotics competitions as benchmarks for AI research - Anderson, Baltes, Cheng - 2011.pdf:pdf},
issn = {02698889},
journal = {Knowledge Engineering Review},
mendeley-groups = {Transfer Report},
number = {1},
pages = {11--17},
title = {{Robotics competitions as benchmarks for AI research}},
volume = {26},
year = {2011}
}

@article{Kendama,
author = {Namiki, Akio and Itoi, Naoki},
doi = {10.1109/HUMANOIDS.2014.7041429},
file = {:home/lynchxps/Documents/literature/Ball Catching in Kendama Game by Estimating Grasp Conditions Based on a High-Speed Vision System and TactileSensors.pdf:pdf},
isbn = {9781479971749},
issn = {21640580},
journal = {IEEE-RAS International Conference on Humanoid Robots},
mendeley-groups = {HandPaper},
pages = {634--639},
title = {{Ball catching in kendama game by estimating grasp conditions based on a high-speed vision system and tactile sensors}},
volume = {2015-Febru},
year = {2015}
}

@INPROCEEDINGS{COTS, 
author={C. {Smith} and H. I. {Christensen}}, 
booktitle={Proceedings 2007 IEEE International Conference on Robotics and Automation}, 
title={Using COTS to Construct a High Performance Robot Arm}, 
year={2007}, 
volume={}, 
number={}, 
pages={4056-4063}, 
keywords={manipulator dynamics;high performance robot arm;technical specifications;high performance robotic manipulator;ball catching experiment;commercial off-the-shelf components;PowerCube actuator modules;CAN bus communication;Robots;End effectors;Robotics and automation;Cameras;Gravity;Kinematics;Control systems;Humans;Acceleration;Manipulators}, 
doi={10.1109/ROBOT.2007.364102}, 
ISSN={1050-4729}, 
month={April},}

@misc{Schunk3FingerGripper,
  author = {SCHUNK Intec Ltd},
  title = {SDH},
  howpublished = {\url{https://schunk.com/pl_en/gripping-systems/series/sdh/}},
  note = {Accessed: 2019-05-06}
}

@Article{HumanTactile,
author="Westling, G.
and Johansson, R. S.",
title="Factors influencing the force control during precision grip",
journal="Experimental Brain Research",
year="1984",
month="Jan",
day="01",
volume="53",
number="2",
pages="277--284",
abstract="A small object was gripped between the tips of the index finger and thumb and held stationary in space. Its weight and surface structure could be changed between consecutive lifting trials, without changing its visual appearance. The grip force and the vertical lifting force acting on the object, as well as the vertical position of the object were continuously recorded. Likewise, the minimal grip force necessary to prevent slipping, was measured. The difference between this minimal force and the employed grip force, was defined as the safety margin to prevent slipping.",
issn="1432-1106",
doi="10.1007/BF00238156",
url={"https://doi.org/10.1007/BF00238156"}
}

@article{iCub,
author = {Tomo, Tito Pradhono and Regoli, Massimo and Schmitz, Alexander and Natale, Lorenzo and Kristanto, Harris and Somlor, Sophon and Jamone, Lorenzo and Metta, Giorgio and Sugano, Shigeki},
doi = {10.1109/LRA.2018.2812915},
file = {:home/lynchxps/Documents/literature/ANewSiliconeStructureforuSkin.pdf:pdf},
issn = {2377-3766},
journal = {IEEE Robotics and Automation Letters},
mendeley-groups = {HandPaper},
number = {c},
pages = {1--1},
title = {{A New Silicone Structure for uSkin - a Soft, Distributed, Digital 3-axis Skin Sensor - and its Integration on the Humanoid Robot iCub}},
url = {http://ieeexplore.ieee.org/document/8307485/},
volume = {3766},
year = {2018}
}

@article{ObjectExploration,
author = {Li, Qiang and Haschke, Robert and Ritter, Helge},
doi = {10.1109/HUMANOIDS.2015.7363434},
file = {:home/lynchxps/Documents/literature/A Visuo-Tactile Control Framework for Manipulation and Exploration of Unknown Objects.pdf:pdf},
isbn = {9781479968855},
issn = {21640580},
journal = {IEEE-RAS International Conference on Humanoid Robots},
keywords = {Force,Grasping,Shape,Tactile sensors,Visualization},
mendeley-groups = {HandPaper},
pages = {610--615},
title = {{A visuo-tactile control framework for manipulation and exploration of unknown objects}},
volume = {2015-Decem},
year = {2015}
}

@article{Vizzy,
author = {Paulino, Tiago and Ribeiro, Pedro and Neto, Miguel and Cardoso, Susana and Schmitz, Alexander and Santos-Victor, Jose and Bernardino, Alexandre and Jamone, Lorenzo},
doi = {10.1109/ICRA.2017.7989118},
file = {:home/lynchxps/Documents/literature/LowCost3AxisSoftTactileSensorsForTheHumanFriendlyRobotVizzy.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {HandPaper},
pages = {966--971},
title = {{Low-cost 3-axis soft tactile sensors for the human-friendly robot Vizzy}},
year = {2017}
}

@article{uSkinFingertip,
author = {Tomo, Tito Pradhono and Schmitz, Alexander and Wong, Wai Keat and Kristanto, Harris and Somlor, Sophon and Hwang, Jinsun and Jamone, Lorenzo and Sugano, Shigeki},
doi = {10.1109/LRA.2017.2734965},
file = {:home/lynchxps/Documents/literature/Covering a Robot Fingertip with uSkin$\backslash$: a Soft Electronic Skin with Distributed 3-axis Force Sensitive Elements for Robot Hands.pdf:pdf},
isbn = {9781538626818},
issn = {2377-3766},
journal = {IEEE Robotics and Automation Letters},
mendeley-groups = {HandPaper},
number = {1},
pages = {124--131},
title = {{Covering a Robot Fingertip With uSkin: A Soft Electronic Skin With Distributed 3-Axis Force Sensitive Elements for Robot Hands}},
url = {http://ieeexplore.ieee.org/document/8000399/},
volume = {3},
year = {2018}
}

@article{InHandCP,
abstract = {Grasping and manipulating objects with robotic hands depend largely on the features of the object to be used. Especially, features such as softness and deformability are crucial to take into account during the manipulation tasks. Indeed, positions of the fingers and forces to be applied by the robot hand when manipulating an object must be adapted to the caused deformation. For unknown objects, a previous recognition stage is usually needed to get the features of the object, and the manipulation strategies must be adapted depending on that recognition stage. To obtain a precise control in the manipulation task, a complex object model is usually needed and performed, for example using the Finite Element Method. However, these models require a complete discretization of the object and they are time-consuming for the performance of the manipulation tasks. For that reason, in this paper a new control strategy, based on a minimal spring model of the objects, is presented and used for the control of the robot hand. This paper also presents an adaptable tactile-servo control scheme that can be used in in-hand manipulation tasks of deformable objects. Tactile control is based on achieving and maintaining a force value at the contact points which changes according to the object softness, a feature estimated in an initial recognition stage.},
author = {Delgado, A. and Jara, C. A. and Torres, F.},
doi = {10.1016/j.rcim.2017.03.002},
file = {:home/lynchxps/Documents/Mendeley Desktop/Robotics and Computer – Integrated Manufacturing In-hand recognition and manipulation of elastic objects using a servo-tactile control.pdf:pdf},
issn = {07365845},
journal = {Robotics and Computer-Integrated Manufacturing},
keywords = {Deformable object,Grasping,In-hand manipulation,Tactile servoing},
number = {January},
pages = {102--112},
publisher = {Elsevier Ltd},
title = {{In-hand recognition and manipulation of elastic objects using a servo-tactile control strategy}},
url = {http://dx.doi.org/10.1016/j.rcim.2017.03.002},
volume = {48},
year = {2017}
}

@article{First3DHall,
author = {Ledermann, Christoph and Wirges, Sascha and Oertel, David and Mende, Michael and Woern, Heinz},
doi = {10.1109/INES.2013.6632782},
file = {:home/lynchxps/Documents/literature/Tactile Sensor on a Magnetic Basis using novel 3D Hall sensor First prototypes and results.pdf:pdf},
isbn = {9781479908288},
journal = {INES 2013 - IEEE 17th International Conference on Intelligent Engineering Systems, Proceedings},
mendeley-groups = {HandPaper},
pages = {55--60},
title = {{Tactile sensor on a magnetic basis using novel 3D Hall sensor - First prototypes and results}},
year = {2013}
}

@article{HumanstoHumanoids,
author = {Dahiya, Ravinder S. and Metta, Giorgio and Valle, Maurizio and Sandini, Giulio},
doi = {10.1109/TRO.2009.2033627},
file = {:home/lynchxps/Documents/literature/Tactile Sensing - From Humans to Humanoids.pdf:pdf},
isbn = {1552-3098 VO - 26},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Cutaneous sensing,Extrinsic sensing,Humanoid robots,Robotic skin,Tactile sensing,Touch sensing system},
mendeley-groups = {HandPaper},
number = {1},
pages = {1--20},
title = {{Tactile sensing-from humans to humanoids}},
volume = {26},
year = {2010}
}


@article{Survey,
author = {Howard R. Nicholls and Mark H. Lee},
title ={A Survey of Robot Tactile Sensing Technology},
journal = {The International Journal of Robotics Research},
volume = {8},
number = {3},
pages = {3-30},
year = {1989},
doi = {10.1177/027836498900800301},

URL = { 
        https://doi.org/10.1177/027836498900800301
    
},
eprint = { 
        https://doi.org/10.1177/027836498900800301
    
}
}

@INPROCEEDINGS{TSiCub, 
author={U. {Martinez-Hernandez} and G. {Metta} and T. J. {Dodd} and T. J. {Prescott} and L. {Natale} and N. F. {Lepora}}, 
booktitle={2013 World Haptics Conference (WHC)}, 
title={Active contour following to explore object shape with robot touch}, 
year={2013}, 
volume={}, 
number={}, 
pages={341-346}, 
keywords={biomimetics;dexterous manipulators;force control;object recognition;probability;shape recognition;tactile sensors;active contour following;object shape exploration;robot touch;active tactile perception approach;probabilistic framework;tactile data;biomimetic fingertip sensor;control architecture;perception-action cycle;exploratory procedure;tactile contact;contact force regulation;fingertip active repositioning;optimal position;accurate perception;object recognition;shape extraction;active perception;shape recognition;Shape;Image edge detection;Active contours;Tactile sensors;perception-action;active tactile perception;tactile exploration;naive Bayes classifier;contour following;robotic finger}, 
doi={10.1109/WHC.2013.6548432}, 
ISSN={}, 
month={April},}


@INPROCEEDINGS{BimanualExploration, 
author={N. {Sommer} and M. {Li} and A. {Billard}}, 
booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Bimanual compliant tactile exploration for grasping unknown objects}, 
year={2014}, 
volume={}, 
number={}, 
pages={6400-6407}, 
keywords={compliance control;Gaussian processes;humanoid robots;manipulators;motion control;iCub humanoid robot;Gaussian processes;point cloud;object identification;robots;unknown object grasping;bimanual compliant tactile exploration;Robot kinematics;Three-dimensional displays;Uncertainty;Training;Tactile sensors}, 
doi={10.1109/ICRA.2014.6907804}, 
ISSN={1050-4729}, 
month={May},}

@INPROCEEDINGS{ConveyorBelt, 
author={S. {Escaida Navarro} and D. {Weiss} and D. {Stogl} and D. {Milev} and B. {Hein}}, 
booktitle={ISR/Robotik 2014; 41st International Symposium on Robotics}, 
title={Tracking and Grasping of Known and Unknown Objects from a Conveyor Belt}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-8}, 
keywords={}, 
doi={}, 
ISSN={}, 
month={June},}


@article{James,
author = {Jamone, Lorenzo and Metta, Giorgio and Nori, Francesco and Sandini, Giulio},
doi = {10.1109/ICHR.2006.321376},
file = {:home/lynchxps/Documents/literature/A Humanoid Robot Acting over an Unstructured World.pdf:pdf},
isbn = {142440200X},
issn = {{\textless}null{\textgreater}},
journal = {Proceedings of the 2006 6th IEEE-RAS International Conference on Humanoid Robots, HUMANOIDS},
mendeley-groups = {HandPaper},
pages = {143--150},
title = {{James: A humanoid robot acting over an unstructured world}},
year = {2006}
}


@INPROCEEDINGS{Gifu, 
author={H. {Kawasaki} and T. {Komatsu} and K. {Uchiyama} and T. {Kurimoto}}, 
booktitle={IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)}, 
title={Dexterous anthropomorphic robot hand with distributed tactile sensor: Gifu hand II}, 
year={1999}, 
volume={2}, 
number={}, 
pages={782-787 vol.2}, 
keywords={dexterous manipulators;tactile sensors;servomotors;finite element analysis;distributed sensors;dexterous anthropomorphic robot hand;distributed tactile sensor;Gifu hand II;dexterous object manipulation;Anthropomorphism;Robot sensing systems;Tactile sensors;Fingers;Humans;Humanoid robots;Medical robotics;Force sensors;Orbital robotics;Thumb}, 
doi={10.1109/ICSMC.1999.825361}, 
ISSN={1062-922X}, 
month={Oct},}

@article{TSdexterous,
title = "Tactile sensing in dexterous robot hands — Review",
journal = "Robotics and Autonomous Systems",
volume = "74",
pages = "195 - 220",
year = "2015",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2015.07.015",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001621",
author = "Zhanat Kappassov and Juan-Antonio Corrales and Véronique Perdereau",
keywords = {"Tactile sensing, Tactile sensors, Robot hands, Dexterous manipulation, Tactile sensing application, Review"}

}

@InProceedings{1994TS,
author="Sikka, Pavan
and Zhang, Hong
and Sutphen, Steve",
editor="Yoshikawa, Tsuneo
and Miyazaki, Fumio",
title="Tactile servo: Control of touch-driven robot motion",
booktitle="Experimental Robotics III",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="219--233",
abstract="In this paper, a new approach to tactile sensor-based object manipulation is proposed. The approach makes use of the simple observation that the progress of a manipulation task can be characterized by the tactile images produced by tactile sensors mounted on the fingertips of a robot hand. In analogy to image-based visual servo, a control scheme based upon features derived from tactile images is used to control the movement of a robot arm. The approach is applied to derive a control scheme for the task of rolling a cylindrical pin on a planar surface using a planar robot finger equipped with a tactile array sensor. The tactile features used in the control scheme are derived from a theoretical and experimental study of the variation of the normal stress distribution as a result of applied force. The experiment demonstrates that information from array tactile sensors can be used in a simple, direct and effective manner to control manipulation tasks. This approach is currently being extended to other tasks involving a dextrous multi-fingered robot hand.",
isbn="978-3-540-39355-9"
}

@ARTICLE{ContactControl, 
author={H. {Zhang} and N. N. {Chen}}, 
journal={IEEE Transactions on Robotics and Automation}, 
title={Control of contact via tactile sensing}, 
year={2000}, 
volume={16}, 
number={5}, 
pages={482-495}, 
keywords={manipulator dynamics;tactile sensors;servomechanisms;feedback;tracking;motion control;compliance control;tactile image;feedback;contact control;tactile servo;tactile sensor;edge tracking;object shape construction;touch sensing;compliant motion control;fine manipulation;manipulators;Robot kinematics;Robot sensing systems;Force control;Tactile sensors;Robotic assembly;Robotics and automation;Servomechanisms;Feedback;Robot control;Object recognition}, 
doi={10.1109/70.880799}, 
ISSN={1042-296X}, 
month={Oct},}


@INPROCEEDINGS{Overview, 
author={A. M. {Okamura} and N. {Smaby} and M. R. {Cutkosky}}, 
booktitle={Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)}, 
title={An overview of dexterous manipulation}, 
year={2000}, 
volume={1}, 
number={}, 
pages={255-262 vol.1}, 
keywords={dexterous manipulators;manipulator kinematics;manipulator dynamics;path planning;reviews;robotic dexterous manipulation;kinematics;contact types;forces;grasp planning;quality measures;Humans;Robot sensing systems;Robot kinematics;Fingers;Jacobian matrices;Laboratories;Manipulators;Delta modulation;Force sensors;Tactile sensors}, 
doi={10.1109/ROBOT.2000.844067}, 
ISSN={1050-4729}, 
month={April},}

@article{Delft,
abstract = {This article describes Team Delft's robot winning the Amazon Robotics Challenge 2016. The competition involves automating pick and place operations in semi-structured environments , specifically the shelves in an Amazon warehouse. Team Delft's entry demonstrated that current robot technology can already address most of the challenges in product handling: object recognition, grasping, motion, or task planning; under broad yet bounded conditions. The system combines an industrial robot arm, 3D cameras and a custom gripper. The robot's software is based on the Robot Operating System to implement solutions based on deep learning and other state-of-the-art artificial intelligence techniques, and to integrate them with off-the-shelf components. From the experience developing the robotic system it was concluded that: 1) the specific task conditions should guide the selection of the solution for each capability required, 2) understanding the characteristics of the individual solutions and the assumptions they embed is critical to integrate a performing system from them, and 3) this characterization can be based on 'levels of robot automation'. This paper proposes automation levels based on the usage of information at design or runtime to drive the robot's behaviour, and uses them to discuss Team Delft's design solution and the lessons learned from this robot development experience.},
author = {Corbato, Carlos Hernandez and Bharatheesha, Mukunda and {Van Egmond}, Jeff and Ju, Jihong and Wisse, Martijn},
doi = {10.1109/TII.2018.2800744},
file = {:home/lynchxps/Documents/Mendeley Desktop/Integrating different levels of automation Lessons from winning the amazon robotics challenge 2016 - Corbato et al. - 2018.pdf:pdf},
issn = {15513203},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {Grasping,Manipulators,Motion planning,Object recognition,Robot control},
mendeley-groups = {Transfer Report},
number = {11},
pages = {4916--4926},
title = {{Integrating different levels of automation: Lessons from winning the amazon robotics challenge 2016}},
volume = {14},
year = {2018}
}

@inproceedings{Zhao,
abstract = {In industrial robots, the use of vision sensors is indispensable, which can enhance the robot's industrial intelligence and better help the industrial robot accomplish tasks. But achieving the accuracy and time efficiency together still is a challenge in industrial tasks. In this paper, a new method is presented to track and grasp the moving object. First, the high-resolution depth and RGB sensing are acquired by Kinect v2. Next, a tracking algorithm of improved spatio-temporal context is applied to tracking the moving object, and the gripper position in the base coordinate system is calculated. To accomplish grasping tasks, a linear prediction method is applied to predict the trajectory of the moving object in three dimension space, and the distance between the moving object and the gripper are constantly decreased by a simple grasping strategy. Finally, the tracking system based on the industrial robot is set up in our laboratory. The effectiveness of the proposed method is verified.},
address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
annote = {IEEE International Conference on Real-time Computing and Robotics
(RCAR), Okinawa, JAPAN, JUL 14-18, 2017},
author = {Zhao, Zhou and Huang, Panfeng and Chen, Lu},
booktitle = {2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR)},
file = {:home/lynchxps/Documents/Mendeley Desktop/Visual Tracking and Grasping of Moving Objects and Its Application to an Industrial Robot - Zhao, Huang, Chen - 2017.pdf:pdf},
isbn = {978-1-5386-2035-9},
keywords = {Visual tracking,industrial robotic applications,kalman filter,kinect v2},
organization = {Inst Elect {\&} Elect Engineers; Inst Elect {\&} Elect Engineers Robot {\&} Automat Soc; Harbin Inst Technol; Beijing Inst Technol; Univ Nevada; Univ Electro Commun Tokyo; Chinese Univ Hong Kong; Chinese Acad Sci},
pages = {555--560},
publisher = {IEEE},
title = {{Visual Tracking and Grasping of Moving Objects and Its Application to an Industrial Robot}},
type = {Proceedings Paper},
year = {2017}
}


@article{Detectionandmapping, 
title={Object detection and mapping for service robot tasks}, 
volume={25}, DOI={10.1017/S0263574706003237}, number={2}, 
journal={Robotica}, 
publisher={Cambridge University Press}, 
author={Ekvall, Staffan and Kragic, Danica and Jensfelt, Patric}, 
year={2007},
pages={175–187}}

@article{Allegro,
annote = {This eventually developed into uskin},
author = {Tomo, Tito Pradhono and Wong, Wai Keat and Schmitz, Alexander and Kristanto, Harris and Sarazin, Alexandre and Jamone, Lorenzo and Somlor, Sophon and Sugano, Shigeki},
doi = {10.1109/HUMANOIDS.2016.7803315},
file = {:home/lynchxps/Documents/literature/A Modular, Distributed, Soft, 3-Axis Sensor System for Robot Hands.pdf:pdf},
isbn = {9781509047185},
issn = {21640580},
journal = {IEEE-RAS International Conference on Humanoid Robots},
keywords = {Tactile perception,Novel sensing mechanisms,Graspi},
mendeley-groups = {HandPaper},
pages = {454--460},
title = {{A modular, distributed, soft, 3-axis sensor system for robot hands}},
year = {2016}
}

@article{DynamicObjectManipulation,
author = {Tarvirdizadeh, Bahram and Youseﬁ-Koma, Aghil},
doi = {10.2316/Journal.206.2012.3.206-3626},
file = {:home/lynchxps/Documents/literature/Dynamic Object Manipulation by a Flexible Robotic Arm Theory and Experiment.pdf:pdf},
issn = {1925-7090},
journal = {International Journal of Robotics and Automation},
mendeley-groups = {HandPaper},
number = {3},
title = {{Dynamic Object Manipulation By a Flexible Robotic Arm: Theory and Experiment}},
url = {http://www.actapress.com/PaperInfo.aspx?paperId=43032},
volume = {27},
year = {2012}
}

@article{CatchingSoftly,
abstract = {Catching a fast flying object is particularly challenging as it consists of two tasks: extremely precise estimation of the object's motion and control of the robot's motion. Any small imprecision may lead the fingers to close too abruptly and let the object fly away from the hand before closing. We present a strategy to overcome for sensorimotor imprecision by introducing softness in the catching approach. Soft catching consists of having the robot moves with the object for a short period of time, so as to leave more time for the fingers to close on the object. We use a dynamic system-based control law to generate the appropriate reach and follow motion, which is expressed as a linear parameter varying (LPV) system. We propose a method to approximate the parameters of LPV systems using Gaussian mixture models, based on a set of kinematically feasible demonstrations generated by an offline optimal control framework. We show theoretically that the resulting DS will intercept the object at the intercept point, at the right time with the desired velocity direction. Stability and convergence of the approach are assessed through Lyapunov stability theory. The proposed method is validated systematically to catch three objects that generate elastic contacts and demonstrate important improvement over a hard catching approach.},
address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
author = {Salehian, Seyed Sina Mirrazavi and Khoramshahi, Mahdi and Billard, Aude},
doi = {10.1109/TRO.2016.2536749},
file = {:home/lynchxps/Documents/Mendeley Desktop/A Dynamical System Approach for Softly Catching a Flying Object Theory and Experiment - Salehian, Khoramshahi, Billard - 2016.pdf:pdf},
issn = {1552-3098},
journal = {IEEE TRANSACTIONS ON ROBOTICS},
keywords = {Catching,dynamical system,manipulation planning},
month = {apr},
number = {2},
pages = {462--471},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{A Dynamical System Approach for Softly Catching a Flying Object: Theory and Experiment}},
type = {Article},
volume = {32},
year = {2016}
}


@misc{MLX,
author = {Melexis},
url = {https://cdn.sparkfun.com/assets/e/e/f/2/7/MLX90393-Datasheet-Melexis.PDF},
title = {{MLX90393 Triaxis {\textregistered} Magnetic Node}},
year = {2017}
}


@article{HSSoft,
author = {Jamone, Lorenzo and Natale, Lorenzo and Metta, Giorgio and Sandini, Giulio},
doi = {10.1109/JSEN.2015.2417759},
file = {:home/lynchxps/Documents/literature/Jamone Highly sensitive soft tactile sensors for an anthropomorphic robotic hand 2015 Accepted.pdf:pdf},
isbn = {1530-437X},
issn = {1530437X},
journal = {IEEE Sensors Journal},
keywords = {Tactile sensors,high sensitivity,robotic hand,soft materials},
mendeley-groups = {HandPaper},
number = {8},
pages = {4226--4233},
title = {{Highly sensitive soft tactile sensors for an anthropomorphic robotic hand}},
volume = {15},
year = {2015}
}

@article{KukayouBot,
abstract = {Establishing mobile manipulation as a powerful key technology for the cognitive factory requires mobile manipulation platforms, which at the same time pay attention to industrial requirements, meet requirements of education and research and last, but not least, come with a decent price tag. KUKA has recently launched a major research and development effort towards designing a mobile manipulation platform that meets these requirements and can serve as a reference platform for industry, research and education at the same time. Although the initiative has just left the starting blocks, a first off-spring, the KUKA youBot, an omni-directional mobile manipulator has just seen the light of day. In this paper we report on the development of the first prototypes.},
author = {Bischoff, Rainer and Huggenberger, Ulrich and Prassler, Erwin},
doi = {10.1109/ICRA.2011.5980575},
file = {:home/lynchxps/Documents/Mendeley Desktop/ICRA Communications KUKA youBot – a mobile manipulator for research and education - Bischoff, Huggenberger, Prassler - 2011.pdf:pdf},
isbn = {9781612843865},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {Transfer Report},
pages = {1--4},
publisher = {IEEE},
title = {{KUKA youBot - A mobile manipulator for research and education}},
year = {2011}
}


@inproceedings{Robotiq,
abstract = {This paper presents the implementation of a robust grasp mapping between a 3-finger haptic device (master) and a robotic hand (slave). Mapping is based on a grasp equivalence defined considering the manipulation capabilities of the master and slave devices. The metrics that translate the human hand gesture to the robotic hand workspace are obtained through an analytical user study. This allows a natural control of the robotic hand. The grasp mapping is accomplished defining 4 control modes that encapsulate all the grasps gestures considered.},
address = {Berlin, Heidelberg},
author = {Su{\'{a}}rez-Ruiz, Francisco and Galiana, Ignacio and Tenzer, Yaroslav and Jentoft, Leif P and Howe, Robert D and Ferre, Manuel},
booktitle = {Haptics: Neuroscience, Devices, Modeling, and Applications},
editor = {Auvray, Malika and Duriez, Christian},
file = {:home/lynchxps/Documents/Mendeley Desktop/Grasp Mapping Between a 3-Finger Haptic Device and a Robotic Hand - Su{\'{a}}rez-Ruiz et al. - 2014.pdf:pdf},
isbn = {978-3-662-44193-0},
pages = {275--283},
publisher = {Springer Berlin Heidelberg},
title = {{Grasp Mapping Between a 3-Finger Haptic Device and a Robotic Hand}},
year = {2014}
}

@misc{RobotIQpic,
  author = {robotiq},
  title = {3-Finger Adaptive Robot Gripper},
  howpublished = {\url{https://robotiq.com/products/3-finger-adaptive-robot-gripper}},
  note = {Accessed: 2019-05-06}
}

@misc{RobotIQ2Fingerpic,
  author = {robotiq},
  title = {2-Finger 85 Gripper},
  howpublished = {\url{http://blog.robotiq.com/hs-fs/hub/13401/file-2610836225-jpg/social-suggested-images/3-grippers.jpg?t=1461786315009&amp;width=511}},
  note = {Accessed: 2019-05-06}
}

@misc{RobotIQHandEpic,
  author = {robotiq},
  title = {Hand-E Adaptive Gripper},
  howpublished = {\url{https://robotiq.com/products/hand-e-adaptive-robot-gripper}},
  note = {Accessed: 2019-05-06}
}

@misc{SandiaHand,
  author = {David Szondy},
  title = {Sandia modular robot hand brings a delicate touch to bomb disposal},
  howpublished = {\url{https://newatlas.com/sandia-hand-robot/23742/}},
  note = {Accessed: 2019-05-06}
}

@misc{AllegroHandpic,
  author = {wonikrobotics},
  title = {Allegro Hand is a low-cost and highly adaptive robotic hand},
  howpublished = {\url{http://wiki.wonikrobotics.com/AllegroHandWiki/index.php/Allegro_Hand}},
  note = {Accessed: 2019-05-07}
}

@misc{DLRHandIIpic,
  author = {DLR Institute of Robotics and MEchatronics},
  title = {DLR Hand II in power grasp, picture 6/12},
  howpublished = {\url{https://www.dlr.de/rm/en/desktopdefault.aspx/tabid-3975/6161_read-243/}},
  note = {Accessed: 2019-05-07}
}

@article{ParticleJamming,
abstract = {Gripping and holding of objects are key tasks for robotic manipulators. The development of universal grippers able to pick up unfamiliar objects of widely varying shape and surface properties remains, however, challenging. Most current designs are based on the multifingered hand, but this approach introduces hardware and software complexities. These include large numbers of controllable joints, the need for force sensing if objects are to be handled securely without crushing them, and the computational overhead to decide how much stress each finger should apply and where. Here we demonstrate a completely different approach to a universal gripper. Individual fingers are replaced by a single mass of granular material that, when pressed onto a target object, flows around it and conforms to its shape. Upon application of a vacuum the granular material contracts and hardens quickly to pinch and hold the object without requiring sensory feedback. We find that volume changes of less than 0.5{\%} suffice to grip objects reliably and hold them with forces exceeding many times their weight. We show that the operating principle is the ability of granular materials to transition between an unjammed, deformable state and a jammed state with solid-like rigidity. We delineate three separate mechanisms, friction, suction, and interlocking, that contribute to the gripping force. Using a simple model we relate each of them to the mechanical strength of the jammed state. This advance opens up new possibilities for the design of simple, yet highly adaptive systems that excel at fast gripping of complex objects.},
author = {Brown, Eric and Rodenberg, Nicholas and Amend, John and Mozeika, Annan and Steltz, Erik and Zakin, Mitchell R and Lipson, Hod and Jaeger, Heinrich M},
doi = {10.1073/pnas.1003250107},
file = {:home/lynchxps/Documents/Mendeley Desktop/Universal robotic gripper based on the jamming of granular material - Brown et al. - 2010.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
mendeley-groups = {Particle Jammin},
number = {44},
pages = {18809--18814},
publisher = {National Academy of Sciences},
title = {{Universal robotic gripper based on the jamming of granular material}},
url = {https://www.pnas.org/content/107/44/18809},
volume = {107},
year = {2010}
}


@article{Hasegawa2017,
abstract = {The mapping and assessment of ecosystems is a key component of the MAES initiative. It is essential to analyse the effects of pressures on ecosystem condition, which will impact the ability of ecosystems to deliver multiple services in the long run. The present report provides an overview about available information on ecosystem condition and is proposing a flexible methodology building on the outcomes of the work undertaken for the last years mainly by the European Environment Agency and based on existing data flows, especially from reporting obligations.},
author = {Hasegawa, Shun and Wada, Kentaro and Niitani, Yusuke and Okada, Kei and Inaba, Masayuki},
doi = {10.1109/IROS.2017.8202288},
file = {:home/lynchxps/Documents/Mendeley Desktop/A three-fingered hand with a suction gripping system for picking various objects in cluttered narrow space - Hasegawa et al. - 2017.pdf:pdf},
isbn = {9781538626825},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Gripper and Other End-Effectors,Perception for Gra},
mendeley-groups = {Transfer Report},
pages = {1164--1171},
title = {{A three-fingered hand with a suction gripping system for picking various objects in cluttered narrow space}},
volume = {2017-Septe},
year = {2017}
}

@article{Eppner2018,
abstract = {We describe the winning entry to the Amazon Picking Challenge 2015. From the experience of building this system and competing, we derive several conclusions: (1) We suggest to characterize robotic system building along four key aspects, each of them spanning a spectrum of solutions - modularity vs. integration, generality vs. assumptions, computation vs. embodiment, and planning vs. feedback. (2) To understand which region of each spectrum most adequately addresses which robotic problem, we must explore the full spectrum of possible approaches. (3) For manipulation problems in unstructured environments, certain regions of each spectrum match the problem most adequately, and should be exploited further. This is supported by the fact that our solution deviated from the majority of the other challenge entries along each of the spectra. This is an abridged version of a conference publication.},
author = {Eppner, Clemens and H{\"{o}}fer, Sebastian and Jonschkowski, Rico and Mart{\'{i}}n-Mart{\'{i}}n, Roberto and Sieverling, Arne and Wall, Vincent and Brock, Oliver},
doi = {10.1007/s10514-018-9761-2},
file = {:home/lynchxps/Documents/Mendeley Desktop/Four aspects of building robotic systems lessons from the Amazon Picking Challenge 2015 - Eppner et al. - 2018.pdf:pdf},
issn = {15737527},
journal = {Autonomous Robots},
keywords = {Amazon Picking Challenge,Mobile manipulation,Robotic systems,Warehouse automation},
mendeley-groups = {Transfer Report},
number = {7},
pages = {1459--1475},
publisher = {Springer US},
title = {{Four aspects of building robotic systems: lessons from the Amazon Picking Challenge 2015}},
url = {https://doi.org/10.1007/s10514-018-9761-2},
volume = {42},
year = {2018}
}


@article{MangoTest,
abstract = {Development of non-destructive tools for determining mango ripeness would improve the quality of industrial production of the postharvest processes. This study addresses the creation of a new sensor that combines the capability of obtaining mechanical and optical properties of the fruit simultaneously. It has been integrated into a robot gripper that can handle the fruit obtaining non-destructive measurements of firmness, incorporating two spectrometer probes to simultaneously obtain reflectance properties in the visible and near-infrared, and two accelerometers attached to the rear side of two fingers. Partial least square regression was applied to different combinations of the spectral data obtained from the different sensors to determine the combination that provides the best results. Best prediction of ripening index was achieved using both spectral measurements and two finger accelerometer signals, with R-P(2) = 0.832 and RMSEP of 0.520. These results demonstrate that simultaneous measurement and analysis of the data fusion set improve the robot gripper features, allowing assessment of the quality of the mangoes during pick and place operations.(C) 2017 IAgrE. Published by Elsevier Ltd. All rights reserved.},
address = {525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA},
author = {Cortes, Victoria and Blanes, Carlos and Blasco, Jose and Ortiz, Coral and Aleixos, Nuria and Mellado, Martin and Cubero, Sergio and Talens, Pau},
doi = {10.1016/j.biosystemseng.2017.08.005},
file = {:home/lynchxps/Documents/Mendeley Desktop/Visual Tracking and Grasping of Moving Objects and Its Application to an Industrial Robot - Zhao, Huang, Chen - 2017(2).pdf:pdf},
issn = {1537-5110},
journal = {BIOSYSTEMS ENGINEERING},
keywords = {Accelerometer,Chemometrics,Non-destructive sensor,Spectrometry,Tactile sensor},
month = {oct},
pages = {112--123},
publisher = {ACADEMIC PRESS INC ELSEVIER SCIENCE},
title = {{Integration of simultaneous tactile sensing and visible and near-infrared reflectance spectroscopy in a robot gripper for mango quality assessment}},
type = {Article},
volume = {162},
year = {2017}
}

@inproceedings{APCinhandproxandcontact,
abstract = {We describe the grasping and manipulation strategy that we employed at the autonomous track of the Robotic Grasping and Manipulation Competition at IROS 2016. A salient feature of our architecture is the tight coupling between visual (Asus Xtion) and tactile perception (Robotic Materials), to reduce the uncertainty in sensing and actuation. We demonstrate the importance of tactile sensing and reactive control during the final stages of grasping using a Kinova Robotic arm. The set of tools and algorithms for object grasping presented here have been integrated into the open-source Robot Operating System (ROS). We have focused exclusively on the manipulation aspect (Track 1) of the competition as the bin-picking task (Track 2) would require a different perception strategy, focusing more on object identification.},
address = {Cham},
author = {Patel, Radhen and Curtis, Rebeca and Romero, Branden and Correll, Nikolaus},
booktitle = {Robotic Grasping and Manipulation},
editor = {Sun, Yu and Falco, Joe},
file = {:home/lynchxps/Documents/Mendeley Desktop/Data-driven grasp synthesis-A survey - Bohg et al. - 2014(2).pdf:pdf},
isbn = {978-3-319-94568-2},
pages = {146--160},
publisher = {Springer International Publishing},
title = {{Improving Grasp Performance Using In-Hand Proximity and Contact Sensing}},
year = {2018}
}

@article{IRPowerLines,
abstract = {This paper describes the development of a mobile robot capable of clearing such obstacles as counterweights, anchor clamps, and torsion tower. The mobile robot walks on overhead ground wires in 500KV power tower. Its ultimate purpose is to automate to inspect the defect of power transmission line. The robot with 13 motors is composed of two arms, two wheels, two claws, two wrists, etc. Each arm has 4 degree of freedom. Claws are also mounted on the arms. An embedded computer based on PC/104 is chosen as the core of control system. Visible light and thermal infrared cameras are installed to obtain the video and temperature information, and the communication system is based on wireless LAN TCP/IP protocol. A prototype robot was developed with careful considerations of mobility. The new sensor configuration is used for the claw to grasp the overhead ground wires. The bridge is installed in the torsion tower for the robot easy to cross obstacles. The new posture plan is proposed for obstacles cleaning in the torsion tower. Results of experiments demonstrate that the robot can be applied to execute the navigation and inspection tasks.},
address = {ZIEGLERGASSE 14, VIENNA, EUROPEAN UNION 1070, AUSTRIA},
author = {Li, Zheng and Ruan, Yi},
file = {:home/lynchxps/Documents/Mendeley Desktop//Automated cutting in the food industry using computer vision - Daley, Arif - 2012.pdf:pdf},
issn = {1729-8806},
journal = {INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS},
keywords = {inspection,navigation,power transmission lines,robot},
month = {dec},
number = {4},
pages = {107--112},
publisher = {I-TECH EDUCATION AND PUBLISHING},
title = {{Autonomous Inspection Robot for Power Transmission Lines Maintenance While Operating on the Overhead Ground Wires}},
type = {Article},
volume = {7},
year = {2010}
}

@article{TactileMango,
abstract = {The objective of the study was to evaluate the use of a robot gripper in the assessment of mango (cv. ``Osteen{\{}''{\}}) firmness as well as to establish relationships between the non-destructive robot gripper measurements with embedded accelerometers in the fingers and the ripeness of mango fruit. Intact mango fruit was handled and manipulated by the robot gripper, and the major physicochemical properties related with their ripening index were analyzed. Partial least square regression models (PLS) were developed to explain these properties according to the variables extracted from the accelerometer signals. Correlation coefficients of 0.925, 0.892, 0.893, and 0.937 with a root-mean-square error of prediction of 2.524 N/mm, 1.579 A degrees Brix, 3.187, and 0.517, were obtained for the prediction of fruit mechanical firmness, total soluble solids, flesh luminosity, and ripening index, respectively. This research showed that it is possible to assess mango firmness and ripeness during handling with a robot gripper.},
address = {233 SPRING ST, NEW YORK, NY 10013 USA},
author = {Blanes, C and Cortes, V and Ortiz, C and Mellado, M and Talens, P},
doi = {10.1007/s11947-015-1548-2},
file = {:home/lynchxps/Documents/Mendeley Desktop/Non-Destructive Assessment of Mango Firmness and Ripeness Using a Robotic Gripper - Blanes et al. - 2015(2).pdf:pdf},
issn = {1935-5130},
journal = {FOOD AND BIOPROCESS TECHNOLOGY},
keywords = {Firmness,Mango,Non-destructive,Ripening index,Robot gripper},
month = {sep},
number = {9},
pages = {1914--1924},
publisher = {SPRINGER},
title = {{Non-Destructive Assessment of Mango Firmness and Ripeness Using a Robotic Gripper}},
type = {Article},
volume = {8},
year = {2015}
}


@article{FingertipEmitterReceiverMovingObjectII,
abstract = {This paper presents a cost-efficient, real-time vision-sensor system for identifying, locating and tracking objects that are unknown and randomly placed on a moving conveyor belt. The visual information obtained from a conventional frame-store unit and an end-effector based proximity sensor outputs are incorporated in a fuzzy-logic control algorithm to make the robotic manipulator grasp moving objects. The robot movements are going to be the result of the comparative measurements made by the sensors after the motion of the moving target is predicted and the gripper is brought into a zone close to the object to be grasped by the application of a vision system. The mobile object is traced by controlling the motion of the end-effector with an end-effector based infrared proximity sensors and conveyor position encoder by keeping the gripper's axis to pass through a median plane of the moving object. With this procedure and using the fuzzy-logic control, the system is adapted to pursue of a mobile object. Laboratory experiments are presented to demonstrate the performance Of this system, (C) 1999 John Wiley {\&} Sons, Inc.},
address = {605 THIRD AVE, NEW YORK, NY 10158-0012 USA},
author = {Konukseven, I and Kaftanoglu, B},
doi = {10.1002/(SICI)1097-4563(199911)16:11<651::AID-ROB4>3.0.CO;2-N},
file = {:home/lynchxps/Documents/Mendeley Desktop/Multisensor controlled robot system for recognizing and tracking moving multiple objects - Konukseven, Kaftanoglu - 1999.pdf:pdf},
issn = {0741-2223},
journal = {JOURNAL OF ROBOTIC SYSTEMS},
month = {nov},
number = {11},
pages = {651--665},
publisher = {JOHN WILEY {\&} SONS INC},
title = {{Multisensor controlled robot system for recognizing and tracking moving multiple objects}},
type = {Article},
volume = {16},
year = {1999}
}

@inproceedings{FingertipEmitterReceiverMovingObject,
abstract = {A multisensor controlled robotic tracking and automatic pick and place system is presented in this paper. The system is designed for recognizing and tracking an object which is selected from multiple objects that are unknown and randomly placed on a moving conveyor belt, using a vision, infrared and encoder sensors in the feedback loop. The robot tracks the parts and transfers them to the proper pallets. We address the use of vision system for identifying and locating objects on a moving conveyor belt, besides we address the use of vision, infrared and encoder sensors for dynamically servoing a manipulator for object tracking, grasping and placing. Laboratory experiments are presented to demonstrate the performance of this system.},
address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
annote = {1997 IEEE/RSJ International Conference on Intelligent Robot and Systems
- Innovative Robotics for Real-World Applications (IROS 97), GRENOBLE,
FRANCE, SEP 07-11, 1997},
author = {Konukseven, I and Kaftanoglu, B and Balkan, T},
booktitle = {IROS `97 - PROCEEDINGS OF THE 1997 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOT AND SYSTEMS: INNOVATIVE ROBOTICS FOR REAL-WORLD APPLICATIONS, VOLS 1-3},
file = {:home/lynchxps/Documents/Mendeley Desktop/Multisensor controlled robotic tracking and automatic pick and place - Konukseven, Kaftanoglu, Balkan - 1996.pdf:pdf},
isbn = {0-7803-4120-1},
organization = {IEEE Ind Electr Soc; IEEE Robot {\&} Automat Soc; Robot Soc Japan; Soc Instrumentat {\&} Control Engineers; New Technol Fdn},
pages = {1356--1362},
publisher = {IEEE},
title = {{Multisensor controlled robotic tracking and automatic pick and place}},
type = {Proceedings Paper},
year = {1996}
}

@inproceedings{2000Konukseven,
abstract = {This paper presents a cost-efficient end-effector based infrared proximity sensor integration system and the implementation of fuzzy-logic control algorithm. End-effector sensor outputs are incorporated in a fuzzy-logic control algorithm to make the robotic manipulator grasp objects on a moving conveyor belt. The robot movements are going to be the result of the comparative measurements made by the sensors after the motion of the moving target is predicted and the gripper is brought into a zone close to the object to be grasped by the application of a vision system.},
address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
annote = {4th International Conference on Knowledge-Based Intelligent Engineering
Systems and Allied Technologies, UNIV BRIGHTON, BRIGHTON, ENGLAND, AUG
30-31, 2000},
author = {Konukseven, E I and Kaftanoglu, B},
booktitle = {KES'2000: FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ENGINEERING SYSTEMS {\&} ALLIED TECHNOLOGIES, VOLS 1 AND 2, PROCEEDINGS},
editor = {{Howlett, RJ and Jain}, LC},
file = {:home/lynchxps/Documents/Mendeley Desktop/Robot end-effector based sensor integration for tracking moving parts - Konukseven, Kaftanoglu - 2000.pdf:pdf},
isbn = {0-7803-6400-7},
organization = {IEE; IEEE},
pages = {628--634},
publisher = {IEEE},
title = {{Robot end-effector based sensor integration for tracking moving parts}},
type = {Proceedings Paper},
year = {2000}
}

@article{AnthroHandReview,
abstract = {This paper presents a review on main topic regarding to anthropomor-phic robotic hands developed in the last years, taking into account the more important mechatronics designs submit on the literature, and ma-king a comparison between them. The next chapters deepen on level of anthropomorphism and dexterity in advanced actuated hands and upper limbs prostheses, as well as a brief overview on issues such as grasping, transmission mechanisms, sensory and actuator system, and also a short introduction on under-actuated robotic hands is reported. Resumen Este art{\'{i}}culo presenta una revisi{\'{o}}n de los principales desarrollos que se han hecho en los {\'{u}}ltimos a{\~{n}}os en manos rob{\'{o}}ticas antropom{\'{o}}rficas. Las primeras secciones tratan temas como el grado de antropomorfismo y de destreza en las manos rob{\'{o}}ticas m{\'{a}}s avanzadas, incluyendo una comparaci{\'{o}}n entre ellas. Tambi{\'{e}}n se abordan temas como la capacidad de agarre de los efectores finales, los mecanismos de trasmisi{\'{o}}n, el sistema actuador y sens{\'{o}}rico, y se hace una breve introducci{\'{o}}n al tema de manos rob{\'{o}}ticas subactuadas. Palabras clave: antropomorfismo, rob{\'{o}}tica humanoide, manos rob{\'{o}}ticas diestras, manos rob{\'{o}}ticas subactuadas. Anthropomorphic robotic hAnds: A review 281 Ingenier{\'{i}}a y Desarrollo. Universidad del Norte. Vol. 32 n.° 2: 279-313, 2014 ISSN: 0122-3461 (impreso) 2145-9371 (on line)},
author = {{Gama Melo}, Erika Nathalia and {Avil{\'{e}}s S{\'{a}}nchez}, Oscar Fernando and {Amaya Hurtado}, Dar{\'{i}}o},
doi = {10.14482/inde.32.2.4715},
file = {:home/lynchxps/Documents/Mendeley Desktop/Anthropomorphic robotic hands a review - Gama Melo, Avil{\'{e}}s S{\'{a}}nchez, Amaya Hurtado - 2014.pdf:pdf},
isbn = {8523259600},
issn = {01223461},
journal = {Ingenier{\'{i}}a Y Desarrollo},
number = {2},
pages = {279--313},
title = {{Anthropomorphic robotic hands: a review}},
url = {http://rcientificas.uninorte.edu.co/index.php/ingenieria/article/view/4715/6356},
volume = {32},
year = {2014}
}


@INPROCEEDINGS{Mahmoud2010, 
author={R. {Mahmoud} and A. {Ueno} and S. {Tatsumi}}, 
booktitle={2010 10th IEEE-RAS International Conference on Humanoid Robots}, 
title={Dexterous mechanism design for an anthropomorphic artificial hand: Osaka City University Hand I}, 
year={2010}, 
volume={}, 
number={}, 
pages={180-185}, 
keywords={artificial limbs;dexterous manipulators;dexterous mechanism design;anthropomorphic artificial hand;Osaka city university hand I;anthropomorphic robot hand;prosthetic hand;planar bar linkage mechanism;hand grasping function;different shape object handling;Fingers;Joints;Humans;Thumb;Robots;Actuators;Wrist}, 
doi={10.1109/ICHR.2010.5686843}, 
ISSN={2164-0572}, 
month={Dec},}

@article{pneumaticAnthropomorphicHand,
abstract = {Abstract This work deals with a pneumatically actuated hand composed of four fingers and an opposable thumb. Mechanisms to convert actuator motion into phalanx rotation were studied to make each finger as similar as possible to the human specimen. Force tactile sensors are disposed along the phalanxes to allow a closed-loop force control, while the thumb position is sensorized by a potentiometer and hence position controlled. Each component is controlled by fuzzy logic. This solution allowed the existing strong nonlinearities to be easily managed. A fuzzy supervisor applies a grasping strategy whose target is an approximate identification of the shape and size of an object to grasp it most efficiently with the disposable fingers. {\textcopyright}2000 John Wiley {\&} Sons, Inc.},
author = {Raparelli, T and Mattiazzo, G and Mauro, S and Velardocchia, M},
doi = {10.1002/(SICI)1097-4563(200001)17:1<1::AID-ROB1>3.0.CO;2-S},
file = {:home/lynchxps/Documents/Mendeley Desktop/Design and development of a pneumatic anthropomorphic hand - Raparelli et al. - 2000.pdf:pdf},
journal = {Journal of Robotic Systems},
mendeley-groups = {Transfer Report},
number = {1},
pages = {1--15},
title = {{Design and development of a pneumatic anthropomorphic hand}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/{\%}28SICI{\%}291097-4563{\%}28200001{\%}2917{\%}3A1{\%}3C1{\%}3A{\%}3AAID-ROB1{\%}3E3.0.CO{\%}3B2-S},
volume = {17},
year = {2000}
}

@article{RBOHand2,
abstract = {The usefulness and versatility of a robotic end-effector depends on the diversity of grasps it can accomplish and also on the complexity of the control methods required to achieve them. We believe that soft hands are able to provide diverse and robust grasping with low control complexity. They possess many mechanical degrees of freedom and are able to implement complex deformations. At the same time, due to the inherent compliance of soft materials, only very few of these mechanical degrees have to be controlled explicitly. Soft hands therefore may combine the best of both worlds. In this paper, we present RBO Hand 2, a highly compliant, underactuated, robust, and dexterous anthropomorphic hand. The hand is inexpensive to manufacture and the morphology can easily be adapted to specific applications. To enable efficient hand design, we derive and evaluate computational models for the mechanical properties of the hand's basic building blocks, called PneuFlex actuators. The versatility of RBO Hand 2 is evaluated by implementing the comprehensive Feix taxonomy of human grasps. The manipulator's capabilities and limits are demonstrated using the Kapandji test and grasping experiments with a variety of objects of varying weight. Furthermore, we demonstrate that the effective dimensionality of grasp postures exceeds the dimensionality of the actuation signals, illustrating that complex grasping behavior can be achieved with relatively simple control.},
author = {Deimel, Raphael and Brock, Oliver},
doi = {10.1177/0278364915592961},
file = {:home/lynchxps/Documents/Mendeley Desktop/A novel type of compliant and underactuated robotic hand for dexterous grasping - Deimel, Brock - 2016.pdf:pdf},
journal = {The International Journal of Robotics Research},
number = {1-3},
pages = {161--185},
title = {{A novel type of compliant and underactuated robotic hand for dexterous grasping}},
url = {https://doi.org/10.1177/0278364915592961},
volume = {35},
year = {2016}
}

@article{HumanIR,
abstract = {Perceiving the environment is crucial in any application relatd to mobile robotics research. In this paper, a new approach to real-time human detection through processing video captured by a thermal infrared camera mounted on the autonomous mobile platform mSecurit (TM) is introduced. The approach starts with a phase of static analysis for the detection of human candidates through some classical image processing techniques such as image normalization and thresholding. Then, the proposal starts a dynamic image analysis phase based in optical flow or image difference. Optical flow is used when the robot is moving, whilst image difference is the preferred method when the mobile platform is still. The results of both phases are compared to enhance the human segmentation by infrared camera. Indeed, optical flow or image difference will emphasize the foreground hot spot areas obtained at the initial human candidates' detection. (C) 2010 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
annote = {3rd International Work-Conference on the Interplay Between Natural and
Artificial Computation, Santiago de Compostela, SPAIN, JUN 22-26, 2009},
author = {Fernandez-Caballero, Antonio and {Carlos Castillo}, Jose and Martinez-Cantos, Javier and Martinez-Tomas, Rafael},
doi = {10.1016/j.robot.2010.06.002},
file = {:home/lynchxps/Documents/Mendeley Desktop/Optical flow or image subtraction in human detection from infrared camera on mobile robot - Fernandez-Caballero et al. - 2010.pdf:pdf},
issn = {0921-8890},
journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
keywords = {Image subtraction,Infrared camera,Mobile robot,Optical flow,Surveillance system},
month = {dec},
number = {12, SI},
pages = {1273--1281},
publisher = {ELSEVIER SCIENCE BV},
title = {{Optical flow or image subtraction in human detection from infrared camera on mobile robot}},
type = {Article; Proceedings Paper},
volume = {58},
year = {2010}
}

@article{OptiTrack,
abstract = {Image-guided interventions enable the surgeon to display the position of
instruments and devices with respect to the patient's imaging studies
during surgery by means of a tracker device. Optical trackers are
commonly chosen for many surgical applications when high accuracy and
robustness are required. OptiTrack is a multicamera optical tracker
whose number of sensors and their spatial configuration can be adapted
to the application requirements, making it suitable for surgical
settings. Nonetheless, no extensive studies of its accuracy are
available. The purpose of this paper was to evaluate an eight-camera
optical tracker in terms of accuracy, miscalibration sensitivity, camera
occlusions, and tool detection in a feasible clinical setup. We studied
the tracking accuracy of the system using a robotic arm (similar to mu m
precision) as the gold standard, a single reflective marker, and various
tracked objects while the system was installed in an operating room.
Miscalibration sensitivity was 0.16 degrees. Mean target error was 0.24
mm for a single marker, decreasing to 0.05 mm for tracked tools.
Single-marker error increased up to 1.65 mm when five cameras where
occluded although 75{\%} of the working volume showed an error lower than
0.23 mm. The accuracy was sufficient for navigating the collimator in
intraoperative electron radiation therapy, improving redundancy and
allowing large-working volumes. The tracker assessment we present and
the validated miscalibration protocol are important contributions to
image-guided surgery, where the choice of the tracker is critical and
the knowledge of the accuracy in situations of camera occlusion is
mandatory during surgical navigation.},
address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
author = {Marinetto, Eugenio and Garcia-Mato, David and Garcia, Alonso and Martinez, Santiago and Desco, Manuel and Pascau, Javier},
doi = {10.1109/ACCESS.2018.2878323},
file = {:home/lynchxps/Documents/Mendeley Desktop/Multicamera Optical Tracker Assessment for Computer Aided Surgery Applications - Marinetto et al. - 2018.pdf:pdf},
issn = {2169-3536},
journal = {IEEE ACCESS},
keywords = {Computer aided interventions; infrared tracking; multicamera optical tracker; optical tracking},
pages = {64359--64370},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{Multicamera Optical Tracker Assessment for Computer Aided Surgery Applications}},
type = {Article},
volume = {6},
year = {2018}
}

@misc{RobotIQVisionPic,
  author = {Karine Simard},
  title = {New Robotiq Vision System Breaks Down Integration Barriers},
  howpublished = {\url{https://blog.robotiq.com/new-robotiq-vision-system-breaks-down-integration-barriers}},
  note = {Accessed: 2019-05-11}
}

@inproceedings{CloseWallFollowing,
abstract = {In this paper we describe the design and implementation of a unique proportional whisker sensor and our general behaviour based software architecture. The Architecture for Behaviour Based Agents (ABBA) is used to realise purposive mobile robot navigation in a cluttered indoor environment. The whisker was developed specifically to meet the requirements of high speed and close wall following. We also discuss the specific architecture we have constructed.},
address = {345 E 47TH ST, NEW YORK, NY 10017},
annote = {1996 IEEE/RSJ International Conference on Intelligent Robots and Systems
- Robotic Intelligence Interacting with Dynamic Worlds (IROS 96), SENRI
LIFE SCI CTR, OSAKA, JAPAN, NOV 04-08, 1996},
author = {Jung, D and Zelinsky, A},
booktitle = {IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3},
file = {:home/lynchxps/Documents/Mendeley Desktop/Whisker based mobile robot navigation - Jung, Zelinsky - 1996.pdf:pdf},
isbn = {0-7803-3214-8},
keywords = {behaviour,navigation,sensor,whisker},
organization = {IEEE Ind Electr Soc; IEEE Robot {\&} Automat Soc; Robot Soc Japan; Soc Instrument {\&} Control Engineers; New Technol Fdn},
pages = {497--504},
publisher = {I E E E},
title = {{Whisker based mobile robot navigation}},
type = {Proceedings Paper},
year = {1996}
}

@article{TactilePerception,
abstract = {In recent years, autonomous robots have increasingly been deployed in unknown environments and required to manipulate or categorize unknown objects. In order to cope with these unfamiliar situations, improvements must be made both in sensing technologies and in the capability to autonomously train perception models. In this paper, we explore this problem in the context of tactile surface identification and categorization. Using a highly-discriminant tactile probe based upon large bandwidth, triple axis accelerometer that is sensitive to surface texture and material properties, we demonstrate that unsupervised learning for surface identification with this tactile probe is feasible. To this end, we derived a Bayesian nonparametric approach based on Pitman-Yor processes to model power-law distributions, an extension of our previous work using Dirichlet processes Dallaire et al. (2011). When tested against a large collection of surfaces and without providing the actual number of surfaces, the tactile probe combined with our proposed approach demonstrated near-perfect recognition in many cases and achieved perfect recognition given the right conditions. We consider that our combined improvements demonstrate the feasibility of effective autonomous tactile perception systems. (C) 2013 Elsevier B.V. All rights reserved.},
address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
author = {Dallaire, Patrick and Giguere, Philippe and Emond, Daniel and Chaib-Draa, Brahim},
doi = {10.1016/j.robot.2013.11.011},
file = {:home/lynchxps/Documents/Mendeley Desktop/Autonomous tactile perception A combined improved sensing and Bayesian nonparametric approach - Dallaire et al. - 2014.pdf:pdf},
issn = {0921-8890},
journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
keywords = {Accelerometer,Bayesian nonparametric methods,Machine learning,Surface and texture identification,Tactile sensing},
month = {apr},
number = {4},
pages = {422--435},
publisher = {ELSEVIER SCIENCE BV},
title = {{Autonomous tactile perception: A combined improved sensing and Bayesian nonparametric approach}},
type = {Article},
volume = {62},
year = {2014}
}

@article{FlyingObject,
Author = {Salehian, Seyed Sina Mirrazavi and Khoramshahi, Mahdi and Billard, Aude},
Title = {{A Dynamical System Approach for Softly Catching a Flying Object: Theory
   and Experiment}},
Journal = {{IEEE TRANSACTIONS ON ROBOTICS}},
Year = {{2016}},
Volume = {{32}},
Number = {{2}},
Pages = {{462-471}},
Month = {{APR}},
Abstract = {{Catching a fast flying object is particularly challenging as it consists
   of two tasks: extremely precise estimation of the object's motion and
   control of the robot's motion. Any small imprecision may lead the
   fingers to close too abruptly and let the object fly away from the hand
   before closing. We present a strategy to overcome for sensorimotor
   imprecision by introducing softness in the catching approach. Soft
   catching consists of having the robot moves with the object for a short
   period of time, so as to leave more time for the fingers to close on the
   object. We use a dynamic system-based control law to generate the
   appropriate reach and follow motion, which is expressed as a linear
   parameter varying (LPV) system. We propose a method to approximate the
   parameters of LPV systems using Gaussian mixture models, based on a set
   of kinematically feasible demonstrations generated by an offline optimal
   control framework. We show theoretically that the resulting DS will
   intercept the object at the intercept point, at the right time with the
   desired velocity direction. Stability and convergence of the approach
   are assessed through Lyapunov stability theory. The proposed method is
   validated systematically to catch three objects that generate elastic
   contacts and demonstrate important improvement over a hard catching
   approach.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Salehian, SSM; Khoramshahi, M; Billard, A (Reprint Author), Ecole Polytech Fed Lausanne, Sch Engn, CH-1015 Lausanne, Switzerland.
   Salehian, Seyed Sina Mirrazavi; Khoramshahi, Mahdi; Billard, Aude, Ecole Polytech Fed Lausanne, Sch Engn, CH-1015 Lausanne, Switzerland.}},
DOI = {{10.1109/TRO.2016.2536749}},
ISSN = {{1552-3098}},
EISSN = {{1941-0468}},
Keywords = {{Catching; dynamical system; manipulation planning}},
Keywords-Plus = {{BALL}},
Research-Areas = {{Robotics}},
Web-of-Science-Categories  = {{Robotics}},
Author-Email = {{sina.mirrazavi@epfl.ch
   mahdi.khoramshahi@epfl.ch
   aude.billard@epfl.ch}},
Funding-Acknowledgement = {{EU {[}600610, H2020-ICT-23-2014]}},
Funding-Text = {{This paper was recommended for publication by Associate Editor V. Krovi
   and Editor T. Murphey upon evaluation of the reviewers' comments. This
   work was supported by EU Projects AlterEgo under Grant 600610 and
   Cogimon under Grant H2020-ICT-23-2014.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{19}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{16}},
Journal-ISO = {{IEEE Trans. Robot.}},
Doc-Delivery-Number = {{DJ6FU}},
Unique-ID = {{ISI:000374306700016}},
DA = {{2019-05-14}},
}

@misc{Silicon,
  author = {MBFiberGlass},
  title = {Polycraft T15 Translucent RTV Addition Cure Silicone Rubber Shore A15},
  howpublished = {\url{https://www.mbfg.co.uk/polycraft-t-15.html}},
  note = {Accessed: 2019-05-27}
}

@article {PassiveDynamicWalker,
	author = {Collins, Steve and Ruina, Andy and Tedrake, Russ and Wisse, Martijn},
	title = {Efficient Bipedal Robots Based on Passive-Dynamic Walkers},
	volume = {307},
	number = {5712},
	pages = {1082--1085},
	year = {2005},
	doi = {10.1126/science.1107799},
	publisher = {American Association for the Advancement of Science},
	abstract = {Passive-dynamic walkers are simple mechanical devices, composed of solid parts connected by joints, that walk stably down a slope. They have no motors or controllers, yet can have remarkably humanlike motions. This suggests that these machines are useful models of human locomotion; however, they cannot walk on level ground. Here we present three robots based on passive-dynamics, with small active power sources substituted for gravity, which can walk on level ground. These robots use less control and less energy than other powered robots, yet walk more naturally, further suggesting the importance of passive-dynamics in human locomotion.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/307/5712/1082},
	eprint = {https://science.sciencemag.org/content/307/5712/1082.full.pdf},
	journal = {Science}
}

@misc{gitIROS,
  author = {Patrick Lynch},
  title = {hand},
  year = {2019},
  publisher = {Bitbucket},
  journal = {Bitbucket repository},
  howpublished = {\url{https://lynchp13@bitbucket.org/lynchp13/hand.git}},
  commit = {1e98b5d}
}